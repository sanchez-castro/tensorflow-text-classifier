{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvuQOfMzR6WF"
   },
   "source": [
    "## Stackoverflow text-classifier\n",
    "\n",
    "* [Github Repo](https://github.com/GoogleCloudPlatform/ai-platform-text-classifier-shap/blob/master/stackoverflow-classifier.ipynb)\n",
    "\n",
    "* [Sara's Blog](https://sararobinson.dev/2019/04/23/interpret-bag-of-words-models-shap.html)\n",
    "\n",
    "* [Youtube Video Tutorial](https://www.youtube.com/watch?v=_RPHiqF2bSs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4RIij6jVUywt",
    "outputId": "90ef8b0b-2de6-4640-db91-d07b5571aba5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow @ file:///tensorflow-2.5.0-cp37-cp37m-linux_x86_64.whl\n",
      "tensorflow-datasets==4.0.1\n",
      "tensorflow-estimator==2.5.0\n",
      "tensorflow-gcs-config==2.5.0\n",
      "tensorflow-hub==0.12.0\n",
      "tensorflow-metadata==1.1.0\n",
      "tensorflow-probability==0.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u8phGZp1R6WG"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow==1.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1mj1BX_0R6WH"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BYp7ysuvVJj6"
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SswkZaPDR6WH",
    "outputId": "7a9b6962-8349-4fc1-84ef-d4ee9f95c72e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://cloudml-demo-lcm/SO_ml_tags_avocado_188k_v2.csv...\n",
      "- [1 files][276.7 MiB/276.7 MiB]                                                \n",
      "Operation completed over 1 objects/276.7 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp 'gs://cloudml-demo-lcm/SO_ml_tags_avocado_188k_v2.csv' ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JpRAhJTGR6WI",
    "outputId": "aceca3a0-8dc2-43ad-af07-6d784d47a5c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Size is 277 MegaBytes \n"
     ]
    }
   ],
   "source": [
    "file = os.path.join('.','SO_ml_tags_avocado_188k_v2.csv')\n",
    "size = round(os.stat(file).st_size/(1024*1024))\n",
    "print('File Size is {} MegaBytes '.format(size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QlJE4rYfR6WI",
    "outputId": "16acfffa-51f9-45cb-a0a9-6e7a12f56d4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adc.json  sample_data  SO_ml_tags_avocado_188k_v2.csv\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Lpx9AiXRR6WJ"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('SO_ml_tags_avocado_188k_v2.csv', names=['tags', 'original_tags', 'text'], header=0)\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1RfX5FrsR6WJ"
   },
   "outputs": [],
   "source": [
    "data = data.drop(columns=['original_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rdRMoJ2WR6WJ"
   },
   "outputs": [],
   "source": [
    "#get rid of any order inherited from the table\n",
    "data = shuffle(data, random_state = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "q0dW-rnvR6WK",
    "outputId": "5c202f11-1516-4874-981a-bb0a9d988339"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182914</th>\n",
       "      <td>tensorflow,keras</td>\n",
       "      <td>avocado image captioning model not compiling b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48361</th>\n",
       "      <td>pandas</td>\n",
       "      <td>return excel file from avocado with flask in f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181447</th>\n",
       "      <td>tensorflow,keras</td>\n",
       "      <td>validating with generator (avocado) i'm trying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66307</th>\n",
       "      <td>pandas</td>\n",
       "      <td>avocado multiindex dataframe selecting data gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11283</th>\n",
       "      <td>pandas</td>\n",
       "      <td>get rightmost non-zero value position for each...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tags                                               text\n",
       "182914  tensorflow,keras  avocado image captioning model not compiling b...\n",
       "48361             pandas  return excel file from avocado with flask in f...\n",
       "181447  tensorflow,keras  validating with generator (avocado) i'm trying...\n",
       "66307             pandas  avocado multiindex dataframe selecting data gi...\n",
       "11283             pandas  get rightmost non-zero value position for each..."
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8_QYCie6R6WK",
    "outputId": "43927aa4-d48a-45bb-b257-58a04902f6a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'avocado image captioning model not compiling because of concatenate layer when mask_zero=true in a previous layer i am new to avocado and i am trying to implement a model for an image captioning project.   i am trying to reproduce the model from image captioning pre-inject architecture (the picture is taken from this paper: where to put the image in an image captioning generator) (but with a minor difference: generating a word at each time step instead of only generating a single word at the end), in which the inputs for the lstm at the first time step are the embedded cnn features. the lstm should support variable input length and in order to do this i padded all the sequences with zeros so that all of them have maxlen time steps.  the code for the model i have right now is the following:    def get_model(model_name, batch_size, maxlen, voc_size, embed_size,          cnn_feats_size, dropout_rate):      # create input layer for the cnn features     cnn_feats_input = input(shape=(cnn_feats_size,))      # normalize cnn features      normalized_cnn_feats = batchnormalization(axis=-1)(cnn_feats_input)      # embed cnn features to have same dimension with word embeddings     embedded_cnn_feats = dense(embed_size)(normalized_cnn_feats)      # add time dimension so that this layer output shape is (none, 1, embed_size)     final_cnn_feats = repeatvector(1)(embedded_cnn_feats)      # create input layer for the captions (each caption has max maxlen words)     caption_input = input(shape=(maxlen,))      # embed the captions     embedded_caption = embedding(input_dim=voc_size,                                  output_dim=embed_size,                                  input_length=maxlen)(caption_input)      # concatenate cnn features and the captions.     # ouput shape should be (none, maxlen + 1, embed_size)     img_caption_concat = concatenate([final_cnn_feats, embedded_caption], axis=1)      # now feed the concatenation into a lstm layer (many-to-many)     lstm_layer = lstm(units=embed_size,                       input_shape=(maxlen + 1, embed_size),   # one additional time step for the image features                       return_sequences=true,                       dropout=dropout_rate)(img_caption_concat)      # create a fully connected layer to make the predictions     pred_layer = timedistributed(dense(units=voc_size))(lstm_layer)      # build the model with cnn features and captions as input and      # predictions output     model = model(inputs=[cnn_feats_input, caption_input],                    outputs=pred_layer)      optimizer = adam(lr=0.0001,                       beta_1=0.9,                       beta_2=0.999,                       epsilon=1e-8)      model.compile(loss=\\'categorical_crossentropy\\',optimizer=optimizer)     model.summary()      return model   the model (as it is above) compiles without any errors (see: model summary) and i managed to train it using my data. however, it doesn\\'t take into account the fact that my sequences are zero-padded and the results won\\'t be accurate because of this. when i try to change the embedding layer in order to support masking (also making sure that i use voc_size + 1 instead of voc_size, as it\\'s mentioned in the documentation) like this:  embedded_caption = embedding(input_dim=voc_size + 1,                              output_dim=embed_size,                              input_length=maxlen, mask_zero=true)(caption_input)   i get the following error:  traceback (most recent call last):   file \"/export/home/.../py3_env/lib/python3.5/site-packages/avocado/python/framework/ops.py\", line 1567, in _create_c_op     c_op = c_api.avocado_finishoperation(op_desc) avocado.python.framework.errors_impl.invalidargumenterror: dimension 0 in both shapes must be equal, but are 200 and 1. shapes are [200] and [1]. for \\'concatenate_1/concat_1\\' (op: \\'concatv2\\') with input shapes: [?,1,200], [?,25,1], [] and with computed input tensors: input[2] = &lt;1&gt;   i don\\'t know why it says the shape of the second array is [?, 25, 1], as i am printing its shape before the concatenation and it\\'s [?, 25, 200] (as it should be).  i don\\'t understand why there\\'d be an issue with a model that compiles and works fine without that parameter, but i assume there\\'s something i am missing.  i have also been thinking about using a masking layer instead of mask_zero=true, but it should be before the embedding and the documentation says that the embedding layer should be the first layer in a model (after the input).   is there anything i could change in order to fix this or is there a workaround to this ?'"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FWwlycaR6WL"
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HDB0KQ02R6WL",
    "outputId": "4ab5060a-a07e-4944-aef3-0c40f8adbfbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tensorflow', 'keras']\n"
     ]
    }
   ],
   "source": [
    "# Encode top tags to multi-hot\n",
    "tags_split = [tags.split(',') for tags in data['tags'].values]\n",
    "print(tags_split[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GtQbUDmKR6WM",
    "outputId": "93d48194-f331-41f0-dc77-8e12c8173c9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['keras' 'matplotlib' 'pandas' 'scikitlearn' 'tensorflow']\n"
     ]
    }
   ],
   "source": [
    "# One hot encoding\n",
    "tag_encoder = MultiLabelBinarizer()\n",
    "tags_encoded = tag_encoder.fit_transform(tags_split)\n",
    "num_tags = len(tags_encoded[0])\n",
    "print(tag_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N6FQpJtNR6WM",
    "outputId": "f2bee9aa-d163-4855-bfcc-09822d893638"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#label vector of the first row\n",
    "tags_encoded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2c44l3mR6WN"
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kfAEEe6bR6WN",
    "outputId": "d76d3f85-b99c-4598-cb0a-ea918da8e027"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 150559\n",
      "Test size: 37640\n"
     ]
    }
   ],
   "source": [
    "# Split our data into train and test sets from the label tags\n",
    "train_size = int(len(data) * .8)\n",
    "print (\"Train size: %d\" % train_size)\n",
    "print (\"Test size: %d\" % (len(data) - train_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "TyNFcwa3R6WN"
   },
   "outputs": [],
   "source": [
    "train_tags = tags_encoded[:train_size]\n",
    "test_tags = tags_encoded[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JdOCVg71R6WO",
    "outputId": "981ec075-35d0-4dc9-ce87-295c1394cea5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3IgpbIZR6WO"
   },
   "source": [
    "\n",
    "\n",
    "### **Creating a class to import in the future**\n",
    "[Keras preprocessing text method](https://keras.io/preprocessing/text/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xDMoIP7bR6WO",
    "outputId": "eec81bd1-462d-4af8-fe68-2a4446bf7312"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocess.py\n",
    "\n",
    "# Pre-processing data: create our tokenizer class\n",
    "from tensorflow.keras.preprocessing import text\n",
    "\n",
    "class TextPreprocessor(object):\n",
    "  def __init__(self, vocab_size):\n",
    "    self._vocab_size = vocab_size\n",
    "    self._tokenizer = None\n",
    "  \n",
    "  def create_tokenizer(self, text_list):\n",
    "    \"\"\"\n",
    "    This class allows to vectorize a text corpus, by turning each text into either a sequence of \n",
    "    integers (each integer being the index of a token in a dictionary) or into a vector where the \n",
    "    coefficient for each token could be binary, based on word count, based on tf-idf.\n",
    "    \"\"\"\n",
    "    tokenizer = text.Tokenizer(num_words=self._vocab_size)\n",
    "    tokenizer.fit_on_texts(text_list)\n",
    "    self._tokenizer = tokenizer\n",
    "\n",
    "  def transform_text(self, text_list):\n",
    "    text_matrix = self._tokenizer.texts_to_matrix(text_list)\n",
    "    return text_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "AzAe1_GmR6WP"
   },
   "outputs": [],
   "source": [
    "# Create vocab from training corpus\n",
    "from preprocess import TextPreprocessor\n",
    "\n",
    "VOCAB_SIZE = 400 # This is a hyperparameter -> take the 400 \"most important words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "wUvdx9LvR6WP"
   },
   "outputs": [],
   "source": [
    "#creating the train/test split\n",
    "train_qs = data['text'].values[:train_size]\n",
    "test_qs = data['text'].values[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "id": "UuGE1IMTW9jx",
    "outputId": "80da3231-5bf7-4601-9b5b-a78a28fbe5a4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'avocado image captioning model not compiling because of concatenate layer when mask_zero=true in a previous layer i am new to avocado and i am trying to implement a model for an image captioning project.   i am trying to reproduce the model from image captioning pre-inject architecture (the picture is taken from this paper: where to put the image in an image captioning generator) (but with a minor difference: generating a word at each time step instead of only generating a single word at the end), in which the inputs for the lstm at the first time step are the embedded cnn features. the lstm should support variable input length and in order to do this i padded all the sequences with zeros so that all of them have maxlen time steps.  the code for the model i have right now is the following:    def get_model(model_name, batch_size, maxlen, voc_size, embed_size,          cnn_feats_size, dropout_rate):      # create input layer for the cnn features     cnn_feats_input = input(shape=(cnn_feats_size,))      # normalize cnn features      normalized_cnn_feats = batchnormalization(axis=-1)(cnn_feats_input)      # embed cnn features to have same dimension with word embeddings     embedded_cnn_feats = dense(embed_size)(normalized_cnn_feats)      # add time dimension so that this layer output shape is (none, 1, embed_size)     final_cnn_feats = repeatvector(1)(embedded_cnn_feats)      # create input layer for the captions (each caption has max maxlen words)     caption_input = input(shape=(maxlen,))      # embed the captions     embedded_caption = embedding(input_dim=voc_size,                                  output_dim=embed_size,                                  input_length=maxlen)(caption_input)      # concatenate cnn features and the captions.     # ouput shape should be (none, maxlen + 1, embed_size)     img_caption_concat = concatenate([final_cnn_feats, embedded_caption], axis=1)      # now feed the concatenation into a lstm layer (many-to-many)     lstm_layer = lstm(units=embed_size,                       input_shape=(maxlen + 1, embed_size),   # one additional time step for the image features                       return_sequences=true,                       dropout=dropout_rate)(img_caption_concat)      # create a fully connected layer to make the predictions     pred_layer = timedistributed(dense(units=voc_size))(lstm_layer)      # build the model with cnn features and captions as input and      # predictions output     model = model(inputs=[cnn_feats_input, caption_input],                    outputs=pred_layer)      optimizer = adam(lr=0.0001,                       beta_1=0.9,                       beta_2=0.999,                       epsilon=1e-8)      model.compile(loss=\\'categorical_crossentropy\\',optimizer=optimizer)     model.summary()      return model   the model (as it is above) compiles without any errors (see: model summary) and i managed to train it using my data. however, it doesn\\'t take into account the fact that my sequences are zero-padded and the results won\\'t be accurate because of this. when i try to change the embedding layer in order to support masking (also making sure that i use voc_size + 1 instead of voc_size, as it\\'s mentioned in the documentation) like this:  embedded_caption = embedding(input_dim=voc_size + 1,                              output_dim=embed_size,                              input_length=maxlen, mask_zero=true)(caption_input)   i get the following error:  traceback (most recent call last):   file \"/export/home/.../py3_env/lib/python3.5/site-packages/avocado/python/framework/ops.py\", line 1567, in _create_c_op     c_op = c_api.avocado_finishoperation(op_desc) avocado.python.framework.errors_impl.invalidargumenterror: dimension 0 in both shapes must be equal, but are 200 and 1. shapes are [200] and [1]. for \\'concatenate_1/concat_1\\' (op: \\'concatv2\\') with input shapes: [?,1,200], [?,25,1], [] and with computed input tensors: input[2] = &lt;1&gt;   i don\\'t know why it says the shape of the second array is [?, 25, 1], as i am printing its shape before the concatenation and it\\'s [?, 25, 200] (as it should be).  i don\\'t understand why there\\'d be an issue with a model that compiles and works fine without that parameter, but i assume there\\'s something i am missing.  i have also been thinking about using a masking layer instead of mask_zero=true, but it should be before the embedding and the documentation says that the embedding layer should be the first layer in a model (after the input).   is there anything i could change in order to fix this or is there a workaround to this ?'"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_qs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "r_jchAnmR6WP"
   },
   "outputs": [],
   "source": [
    "#initializing the class\n",
    "processor = TextPreprocessor(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "EVaPWOHER6WP"
   },
   "outputs": [],
   "source": [
    "#creating the matrix with the words size and the corpus of train qs\n",
    "processor.create_tokenizer(train_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "HfWa9G51R6WP"
   },
   "outputs": [],
   "source": [
    "#Creating the bag of words\n",
    "body_train = processor.transform_text(train_qs)\n",
    "body_test = processor.transform_text(test_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hdKl02XVR6WQ",
    "outputId": "4d19ef6e-a346-46b4-c100-0c6162a23517"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0.\n",
      " 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1.\n",
      " 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      " 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#print the size of the matrix & the first vector of the corpus in train\n",
    "print(len(body_train[0]))\n",
    "print(body_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "WDSdjefnR6WQ"
   },
   "outputs": [],
   "source": [
    "# Save the tokenizer!!! \n",
    "import pickle\n",
    "\n",
    "with open('./processor_state.pkl', 'wb') as f:\n",
    "  pickle.dump(processor, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbV3sp_KR6WQ"
   },
   "source": [
    "## Build and train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "iyWIomS5R6WR"
   },
   "outputs": [],
   "source": [
    "# defining the neural net \n",
    "\n",
    "def create_model(vocab_size, num_tags):\n",
    "    \n",
    "    #Model groups layers into an object with training and inference features.\n",
    "    model = tf.keras.models.Sequential()\n",
    "    \n",
    "    #Input shape = sizeof our matrix vector bag of words\n",
    "    model.add(tf.keras.layers.Dense(50, input_shape=(VOCAB_SIZE,), activation='relu'))\n",
    "    #A hidden layer to 25 nodes\n",
    "    model.add(tf.keras.layers.Dense(25, activation='relu'))\n",
    "    #Output layer to the number of tags that we want to predict\n",
    "    model.add(tf.keras.layers.Dense(num_tags, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QSJMG0z3R6WR",
    "outputId": "36fbcc95-8054-4411-912d-dd16996f13a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                20050     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 130       \n",
      "=================================================================\n",
      "Total params: 21,455\n",
      "Trainable params: 21,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(VOCAB_SIZE, num_tags)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3X7_euOqR6WR",
    "outputId": "cdae82e0-f02e-4c50-e235-70d2528594be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1059/1059 [==============================] - 4s 3ms/step - loss: 0.1492 - accuracy: 0.8522 - val_loss: 0.1066 - val_accuracy: 0.8936\n",
      "Epoch 2/3\n",
      "1059/1059 [==============================] - 3s 2ms/step - loss: 0.1046 - accuracy: 0.8943 - val_loss: 0.1017 - val_accuracy: 0.8947\n",
      "Epoch 3/3\n",
      "1059/1059 [==============================] - 3s 3ms/step - loss: 0.0996 - accuracy: 0.8969 - val_loss: 0.0993 - val_accuracy: 0.8989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2ca41bff50>"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "#_train = input bag of words's array -> features\n",
    "#_tags = labels \n",
    "#epochs =  times where the model will iterate through the entire \n",
    "#batch size = how many elements the model will look at a time to update weights\n",
    "#validation split = validation size \n",
    "\n",
    "model.fit(body_train, train_tags, epochs=3, batch_size=128, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3MvnK5duR6WS",
    "outputId": "91187786-a5f1-42e9-b7c6-630ca2b54246"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295/295 [==============================] - 0s 1ms/step - loss: 0.1026 - accuracy: 0.8965\n",
      "Eval loss/accuracy:[0.10263391584157944, 0.896519660949707]\n"
     ]
    }
   ],
   "source": [
    "print('Eval loss/accuracy:{}'.format(model.evaluate(body_test, test_tags, batch_size=128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "pB3tXOg6R6WS"
   },
   "outputs": [],
   "source": [
    "# Export the model to a file\n",
    "model.save('keras_saved_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0T5IvfDR6WS"
   },
   "source": [
    "## Test our model (locally)\n",
    "\n",
    "1. Instantiate (the saved) model from the file,\n",
    "2. Instantiate the tokenizer\n",
    "3. preprocess the text data input text and transform \n",
    "4. Predict (the sigmoid probability array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WxndrrajR6WT",
    "outputId": "8fde12a9-82ed-46ab-887f-90d2c5d0929e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_prediction.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_prediction.py\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class CustomModelPrediction(object):\n",
    "\n",
    "  def __init__(self, model, processor):\n",
    "    self._model = model\n",
    "    self._processor = processor\n",
    "  \n",
    "  def predict(self, instances, **kwargs):\n",
    "    preprocessed_data = self._processor.transform_text(instances)\n",
    "    predictions = self._model.predict(preprocessed_data)\n",
    "    return predictions.tolist()\n",
    "\n",
    "  @classmethod\n",
    "  def from_path(cls, model_dir):\n",
    "    import os\n",
    "    import tensorflow.keras as keras\n",
    "    model = keras.models.load_model(os.path.join(model_dir,'keras_saved_model.h5'))\n",
    "    with open(os.path.join(model_dir, 'processor_state.pkl'), 'rb') as f:\n",
    "      processor = pickle.load(f)\n",
    "\n",
    "    return cls(model, processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "TzWqf7RwR6WT"
   },
   "outputs": [],
   "source": [
    "# Taking two external questions\n",
    "\n",
    "test_requests = [\n",
    "  \"How to preprocess strings in Keras models Lambda layer? I have the problem that the value passed on to the Lambda layer (at compile time) is a placeholder generated by keras (without values). When the model is compiled, the .eval () method throws the error: You must feed a value for placeholder tensor 'input_1' with dtype string and shape [?, 1] def text_preprocess(x): strings = tf.keras.backend.eval(x) vectors = [] for string in strings: vector = string_to_one_hot(string.decode('utf-8')) vectors.append(vector) vectorTensor = tf.constant(np.array(vectors),dtype=tf.float32) return vectorTensor input_text = Input(shape=(1,), dtype=tf.string) embedding = Lambda(text_preprocess)(input_text) dense = Dense(256, activation='relu')(embedding) outputs = Dense(2, activation='softmax')(dense) model = Model(inputs=[input_text], outputs=outputs) model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy']) model.summary() model.save('test.h5') If I pass a string array into the input layer statically, I can compile the model, but I get the same error if I want to convert the model to tflite. #I replaced this line: input_text = Input(shape=(1,), dtype=tf.string) #by this lines: test = tf.constant(['Hello', 'World']) input_text = Input(shape=(1,), dtype=tf.string, tensor=test) #but calling this ... converter = TFLiteConverter.from_keras_model_file('string_test.h5') tfmodel = converter.convert() #... still leads to this error: InvalidArgumentError: You must feed a value for placeholder tensor 'input_3' with dtype string and shape [2] [[{{node input_3}}]] \",\n",
    "  \"Change the bar item name in Pandas I have a test excel file like: df = pd.DataFrame({'name':list('abcdefg'), 'age':[10,20,5,23,58,4,6]}) print (df) name  age 0    a   10 1    b   20 2    c    5 3    d   23 4    e   58 5    f    4 6    g    6 I use Pandas and matplotlib to read and plot it: import pandas as pd import numpy as np import matplotlib.pyplot as plt import os excel_file = 'test.xlsx' df = pd.read_excel(excel_file, sheet_name=0) df.plot(kind='bar') plt.show() the result shows: enter image description here it use index number as item name, how can I change it to the name, which stored in column name?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-3d0TC1QR6WT",
    "outputId": "d649d8cc-79f2-4d64-ee6f-6fd2fe612cd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tensorflow.python.keras.engine.sequential.Sequential at 0x7f2ca4140450>,\n",
       " <preprocess.TextPreprocessor at 0x7f2cab05f850>)"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model_prediction import CustomModelPrediction\n",
    "\n",
    "classifier = CustomModelPrediction.from_path('.')\n",
    "model, processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "GN22HHvOR6WU"
   },
   "outputs": [],
   "source": [
    "results = classifier.predict(test_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q6P3Ieb-R6WU",
    "outputId": "14381bc5-8efb-4d0e-ea45-e1ceda8a72f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9273104071617126,\n",
       " 2.0946579297742574e-06,\n",
       " 0.00045377016067504883,\n",
       " 0.0005098879337310791,\n",
       " 0.7578976154327393]"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1P3Y8XoiR6WU",
    "outputId": "fcd54daf-2de2-4e99-ac89-eb9eae35b8a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.475283150095493e-06,\n",
       " 0.6833502054214478,\n",
       " 0.729624330997467,\n",
       " 0.0005828738212585449,\n",
       " 4.466549398784991e-06]"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DXZ96m7vR6WU",
    "outputId": "9ee19b06-9ed0-486e-e5a3-bcdb026a9929"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels for text-0:\n",
      "keras\n",
      "tensorflow\n",
      "\n",
      "\n",
      "Predicted labels for text-1:\n",
      "pandas\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(results)):\n",
    "  print('Predicted labels for text-{}:'.format(i))\n",
    "  for idx, val in enumerate(results[i]):\n",
    "    if val > 0.7:\n",
    "      print(tag_encoder.classes_[idx])\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmN-Qev8R6WU"
   },
   "source": [
    "## Package our model and deploy to AI Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJDEj6cRps8E"
   },
   "source": [
    "## GCP Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PBt9sVbTpHhi",
    "outputId": "0202ccb4-93da-4da2-8bb2-fa65a46d2548"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "\n",
      "\n",
      "To take a quick anonymous survey, run:\n",
      "  $ gcloud survey\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!gcloud config set project gap-testing-322018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IWskGrlMszAe",
    "outputId": "4fa1f815-7873-4ec2-e995-7adb7281264d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [ai_platform/region].\n"
     ]
    }
   ],
   "source": [
    "!gcloud config set ai_platform/region global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TsFNQKcDR6WV",
    "outputId": "1e0e0e3f-debe-4e86-97e9-d0ea7564d393"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://keras_saved_model.h5 [Content-Type=application/octet-stream]...\n",
      "-\n",
      "Operation completed over 1 objects/282.0 KiB.                                    \n",
      "Copying file://processor_state.pkl [Content-Type=application/octet-stream]...\n",
      "-\n",
      "Operation completed over 1 objects/32.0 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "#Copying model and preprocessor to GCS Bucket\n",
    "\n",
    "!gsutil cp keras_saved_model.h5 gs://tex-classification-stackoverflow\n",
    "!gsutil cp processor_state.pkl gs://tex-classification-stackoverflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EszUXBo-R6WV"
   },
   "source": [
    "### Source Distribution (or “sdist”)\n",
    "A distribution format (usually generated using python setup.py sdist) that provides metadata and the essential source files needed for installing by a tool like pip, or for generating a Built Distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vwQW8_1vpyUC",
    "outputId": "11dc9b2f-7849-4b09-b206-856b40281abb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile setup.py\n",
    "\n",
    "from setuptools import setup\n",
    "\n",
    "setup(\n",
    "  name=\"so_predict\",\n",
    "  version=\"0.1\",\n",
    "  include_package_data=True,\n",
    "  scripts=[\"preprocess.py\", \"model_prediction.py\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73S3-OQlR6WV",
    "outputId": "cbc92a9f-0e48-4dc2-bb1b-efe157774623"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running sdist\n",
      "running egg_info\n",
      "creating so_predict.egg-info\n",
      "writing so_predict.egg-info/PKG-INFO\n",
      "writing dependency_links to so_predict.egg-info/dependency_links.txt\n",
      "writing top-level names to so_predict.egg-info/top_level.txt\n",
      "writing manifest file 'so_predict.egg-info/SOURCES.txt'\n",
      "reading manifest file 'so_predict.egg-info/SOURCES.txt'\n",
      "writing manifest file 'so_predict.egg-info/SOURCES.txt'\n",
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n",
      "running check\n",
      "warning: check: missing required meta-data: url\n",
      "\n",
      "warning: check: missing meta-data: either (author and author_email) or (maintainer and maintainer_email) must be supplied\n",
      "\n",
      "creating so_predict-0.1\n",
      "creating so_predict-0.1/so_predict.egg-info\n",
      "copying files to so_predict-0.1...\n",
      "copying model_prediction.py -> so_predict-0.1\n",
      "copying preprocess.py -> so_predict-0.1\n",
      "copying setup.py -> so_predict-0.1\n",
      "copying so_predict.egg-info/PKG-INFO -> so_predict-0.1/so_predict.egg-info\n",
      "copying so_predict.egg-info/SOURCES.txt -> so_predict-0.1/so_predict.egg-info\n",
      "copying so_predict.egg-info/dependency_links.txt -> so_predict-0.1/so_predict.egg-info\n",
      "copying so_predict.egg-info/top_level.txt -> so_predict-0.1/so_predict.egg-info\n",
      "Writing so_predict-0.1/setup.cfg\n",
      "creating dist\n",
      "Creating tar archive\n",
      "removing 'so_predict-0.1' (and everything under it)\n",
      "Copying file://./dist/so_predict-0.1.tar.gz [Content-Type=application/x-tar]...\n",
      "/ [1 files][  1.3 KiB/  1.3 KiB]                                                \n",
      "Operation completed over 1 objects/1.3 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!python setup.py sdist\n",
    "!gsutil cp ./dist/so_predict-0.1.tar.gz gs://tex-classification-stackoverflow/packages/so_predict-0.1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SLJT74vMR6WW"
   },
   "outputs": [],
   "source": [
    "# To configure and give access to the API\n",
    "#!glcloud init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8XjLdo7R6WW"
   },
   "source": [
    "To review details visit https://cloud.google.com/ai-platform/prediction/docs/deploying-models#gcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEGD38dPR6WX"
   },
   "source": [
    "https://cloud.google.com/ai-platform/prediction/docs/custom-prediction-routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DYmDAO6PrHTb",
    "outputId": "8001fc91-b266-4034-92f3-5ad10f240432"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please specify a region:\n",
      "(For the global endpoint the region needs to be specified as \n",
      "'global'.)\n",
      " [1] global\n",
      " [2] asia-east1\n",
      " [3] asia-northeast1\n",
      " [4] asia-southeast1\n",
      " [5] australia-southeast1\n",
      " [6] europe-west1\n",
      " [7] europe-west2\n",
      " [8] europe-west3\n",
      " [9] europe-west4\n",
      " [10] northamerica-northeast1\n",
      " [11] us-central1\n",
      " [12] us-east1\n",
      " [13] us-east4\n",
      " [14] us-west1\n",
      " [15] cancel\n",
      "Please enter your numeric choice:  1\n",
      "\n",
      "To make this the default region, run `gcloud config set ai_platform/region global`.\n",
      "\n",
      "\u001b[1;33mWARNING:\u001b[0m To specify a region where the model will deployed on the global endpoint, please use `--regions` and do not specify `--region`. Using [us-central1] by default on https://ml.googleapis.com. Please note that your model will be inaccessible from https://us-central1-ml.googelapis.com\n",
      "\n",
      "Learn more about regional endpoints and see a list of available regions: https://cloud.google.com/ai-platform/prediction/docs/regional-endpoints\n",
      "Using endpoint [https://ml.googleapis.com/]\n",
      "Created ai platform model [projects/gap-testing-322018/models/stackoverflow_pred].\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform models create stackoverflow_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ytjsyYukudPg",
    "outputId": "eab7f050-d56f-4be6-8e16-f2bcedaf3c44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow @ file:///tensorflow-2.5.0-cp37-cp37m-linux_x86_64.whl\n",
      "tensorflow-datasets==4.0.1\n",
      "tensorflow-estimator==2.5.0\n",
      "tensorflow-gcs-config==2.5.0\n",
      "tensorflow-hub==0.12.0\n",
      "tensorflow-metadata==1.1.0\n",
      "tensorflow-probability==0.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRMSYnuBvvZQ"
   },
   "source": [
    "https://cloud.google.com/ai-platform/prediction/docs/runtime-version-list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ayGI1jIPR6WX",
    "outputId": "0a64e963-4544-436d-9248-af394fa04d3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://ml.googleapis.com/]\n"
     ]
    }
   ],
   "source": [
    "!gcloud beta ai-platform versions create v1 \\\n",
    "--model stackoverflow_pred \\\n",
    "--python-version 3.7 \\\n",
    "--runtime-version 2.5 \\\n",
    "--origin gs://tex-classification-stackoverflow/ \\\n",
    "--package-uris gs://tex-classification-stackoverflow/packages/so_predict-0.1.tar.gz \\\n",
    "--prediction-class model_prediction.CustomModelPrediction \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrHG6eVoR6WX"
   },
   "source": [
    "# Generating predictions in our deployed trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VvmfIcOAR6WX"
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/55517871/how-to-preprocess-strings-in-keras-models-lambda-layer\n",
    "# https://stackoverflow.com/questions/55508547/plot-histogram-for-feature-of-array-with-known-and-limited-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FCgK2z7JR6WX",
    "outputId": "14b1a576-cbc5-4390-d2f4-73d64758d814"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing predictions.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile predictions.txt\n",
    "\"How to preprocess strings in Keras models Lambda layer? I have the problem that the value passed on to the Lambda layer (at compile time) is a placeholder generated by keras (without values). When the model is compiled, the .eval () method throws the error\"\n",
    "\"I have a test excel file like:df = pd.DataFrame({'name':list('abcdefg'), 'age':[10,20,5,23,58,4,6]})print (df)name  age0    a   101    b   202    c    53    d   234    e   585    f    46    g    6I use Pandas and matplotlib to read and plot it:import pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport osexcel_file = 'test.xlsx'df = pd.read_excel(excel_file, sheet_name=0)df.plot(kind='bar')plt.show()the result shows: enter image description hereit use index number as item name, how can I change it to the name, which stored in column name?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "LkDyhA8vR6WY"
   },
   "outputs": [],
   "source": [
    "# Getting predictions for our model\n",
    "predictions = !gcloud ai-platform predict --model=stackoverflow_pred --version=v1 --text-instances=predictions.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g_wdFe8MR6WY",
    "outputId": "f7152972-cc92-4386-9c0c-eb5ec456222c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Using endpoint [https://ml.googleapis.com/]',\n",
       " '[[0.5487498044967651, 0.0005612969398498535, 0.01081991195678711, 0.009595274925231934, 0.7237932085990906], [1.426701510354178e-05, 0.6793701648712158, 0.7626110911369324, 0.0008813142776489258, 5.05873958900338e-06]]']"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xMCYdyhWR6WY",
    "outputId": "582a9a28-4c96-40fd-b286-8faa5ee704bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5487498044967651, 0.0005612969398498535, 0.01081991195678711, 0.009595274925231934, 0.7237932085990906]\n",
      "tensorflow\n",
      "\n",
      "\n",
      "[1.426701510354178e-05, 0.6793701648712158, 0.7626110911369324, 0.0008813142776489258, 5.05873958900338e-06]\n",
      "pandas\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sigmoid_arr in eval(predictions[1]):\n",
    "  print(sigmoid_arr)\n",
    "  for idx,probability in enumerate(sigmoid_arr):\n",
    "    if probability > 0.7:\n",
    "      print(tag_encoder.classes_[idx])\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cTiiRLbVR6WY",
    "outputId": "f96c6459-f498-4088-b6ad-ebc70203ad4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['keras' 'matplotlib' 'pandas' 'scikitlearn' 'tensorflow'] \n",
      "\n",
      "[0.5487498044967651, 0.0005612969398498535, 0.01081991195678711, 0.009595274925231934, 0.7237932085990906]\n",
      "tensorflow\n",
      "\n",
      "\n",
      "[1.426701510354178e-05, 0.6793701648712158, 0.7626110911369324, 0.0008813142776489258, 5.05873958900338e-06]\n",
      "pandas\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tag_encoder.classes_, '\\n')\n",
    "\n",
    "for sigmoid_arr in eval(predictions[1]):\n",
    "  print(sigmoid_arr)\n",
    "  for idx,probability in enumerate(sigmoid_arr):\n",
    "    if probability > 0.7:\n",
    "      print(tag_encoder.classes_[idx])\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AarH6YYeR6WY"
   },
   "source": [
    "# Interpreting our model with SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YHpaZoBgxZ-j",
    "outputId": "883fafdf-3f7c-47ee-f541-ade3d4e7c46d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in /usr/local/lib/python3.7/dist-packages (0.39.0)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap) (0.51.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from shap) (1.1.5)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from shap) (0.22.2.post1)\n",
      "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.7/dist-packages (from shap) (0.0.7)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from shap) (1.19.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from shap) (1.4.1)\n",
      "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap) (4.41.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->shap) (57.2.0)\n",
      "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap) (0.34.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2018.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (1.0.1)\n",
      "Collecting colored\n",
      "  Downloading colored-1.4.2.tar.gz (56 kB)\n",
      "\u001b[K     |████████████████████████████████| 56 kB 2.2 MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: colored\n",
      "  Building wheel for colored (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for colored: filename=colored-1.4.2-py3-none-any.whl size=14021 sha256=bd06a5f05cf2804d66a2d696d0b84ec591b5be9a607a376a3075c70d0ae803d7\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/e1/fb/d0e85a8383ff58962319bb81c46e398fa1f4bb9e1feb0f81c4\n",
      "Successfully built colored\n",
      "Installing collected packages: colored\n",
      "Successfully installed colored-1.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install shap\n",
    "!pip install colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xyxvz-NQR6WZ",
    "outputId": "16e28053-8da4-4e2a-eb35-e265d268417b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras is no longer supported, please use tf.keras instead.\n",
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "attrib_data = body_train[:200] ## subset of training data\n",
    "explainer = shap.DeepExplainer(model, attrib_data)\n",
    "\n",
    "num_explanations = 25 # subset of test data\n",
    "shap_vals = explainer.shap_values(body_test[:num_explanations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0COFHtyeR6WZ",
    "outputId": "1fda1964-a7d3-4b5b-d9dc-9c6724f5bffc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 1., ..., 0., 0., 1.],\n",
       "       [0., 1., 1., ..., 1., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_test[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8fn17v5xR6WZ",
    "outputId": "16c5f5bb-56e9-4d7c-e7f3-2c3c72c36ca2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 1,\n",
       " '1': 5,\n",
       " '2': 9,\n",
       " 'a': 7,\n",
       " 'and': 10,\n",
       " 'avocado': 3,\n",
       " 'i': 4,\n",
       " 'in': 8,\n",
       " 'the': 2,\n",
       " 'to': 6}"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = processor._tokenizer.word_index\n",
    "dict(list(words.items())[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iWU7RsP5R6WZ",
    "outputId": "1d13d23b-2226-4571-e8fd-e81dc366c0b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '0', 'the', 'avocado', 'i', '1', 'to', 'a', 'in', '2', 'and', 'is', 'of', 'for', '3', 'x', 'data', 'this', 'with', 'df', 'as', '5', 'it', 'import', '4', 'from', 'gt', 'y', 'that', 'have', 'model', 'dataframe', 'file', 'self', 'but', '00', \"'\", 'my', 'on', 'np', '10', 'train', 'how', 'python', 'if', 'not', 'get', '7', 'line', '6', '01', 'be', 'like', 'lt', 'using', 'c', 'nan', 'am', 'column', 'py', 'name', 'code', 'input', 'index', 'values', 'can', 'size', 'do', 'plot', 'print', 'columns', 'b', 'so', 'value', 'lib', 'shape', 'set', '8', 'test', 'want', 'error', 'are', 'output', 'an', 'true', 'packages', '12', 'use', 'time', 'n', 'batch', 'return', 'or', 'add', 'by', 'def', 'would', 'list', 'when', '9']\n"
     ]
    }
   ],
   "source": [
    "word_lookup = list()\n",
    "for i in words.keys():\n",
    "  word_lookup.append(i)\n",
    "\n",
    "word_lookup = [''] + word_lookup\n",
    "print(word_lookup[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "id": "Gc9Yc1bdR6Wa",
    "outputId": "13c0809e-c0de-4eea-888f-c4231df2c606"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x684 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap.summary_plot(shap_vals, feature_names=word_lookup, class_names=tag_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "bgxncAZhylY2"
   },
   "outputs": [],
   "source": [
    "import colored\n",
    "import re \n",
    "def colorprint(question, pos, neg):\n",
    "  # Split question string on multiple chars\n",
    "  q_arr = []\n",
    "  q_filtered = filter(None,re.split(\"[, .()]+\", question))\n",
    "  for i in q_filtered:\n",
    "    q_arr.append(i)\n",
    "\n",
    "  color_str = []\n",
    "  for idx,word in enumerate(q_arr):\n",
    "    if word in pos:\n",
    "      color_str.append(colored.fg(\"blue\") + word)\n",
    "    elif word in neg:\n",
    "      color_str.append(colored.fg(\"light_red\") + word)\n",
    "    else:\n",
    "      color_str.append(colored.fg('black') + word)\n",
    "\n",
    "    # For wrapped printing\n",
    "    if idx % 15 == 0 and idx > 0:\n",
    "      color_str.append('\\n')\n",
    "\n",
    "  print(' '.join(color_str) + colored.fg('black') + \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 749
    },
    "id": "DuRE_y-Kyl9b",
    "outputId": "5c2afd06-e4e7-4a0e-8bde-e2ee42bccacf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-f6bb78129a1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m# Print the predicted labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted labels:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mpred_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbody_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexamples_to_print\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtagprob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_tag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtagprob\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1725\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1727\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1728\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    763\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 764\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3289\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1569 predict_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1559 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1552 run_step  **\n        outputs = model.predict_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1525 predict_step\n        return self(x, training=False)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:255 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 400 but received input with shape (None, 1)\n"
     ]
    }
   ],
   "source": [
    "# Print highlighted signal words for a few questions\n",
    "examples_to_print = [0,7,20,22,24]\n",
    "\n",
    "for i in range(len(examples_to_print)):\n",
    "  \n",
    "  # Print the actual labels\n",
    "  actual = test_tags[examples_to_print[i]]\n",
    "  num_labels = np.sum(actual)\n",
    "\n",
    "  actual_labels = np.argpartition(actual, -num_labels)[-num_labels:]\n",
    "  \n",
    "  # Print the predicted labels\n",
    "  print('Predicted labels:')\n",
    "  pred_tag = model.predict([[body_test[examples_to_print[i]]]])\n",
    "  for idx,tagprob in enumerate(pred_tag[0]):\n",
    "    if tagprob > 0.8:\n",
    "      print(tag_encoder.classes_[idx])\n",
    "  print('\\n')\n",
    "\n",
    "  # Get the highest and lowest signaling words\n",
    "  for idx,tag in enumerate(pred_tag[0]):\n",
    "    if tag > 0.7:\n",
    "      attributions = shap_vals[idx][examples_to_print[i]]\n",
    "      top_signal_words = np.argpartition(attributions, -5)[-5:]\n",
    "      pos_words = []\n",
    "      for word_idx in top_signal_words:\n",
    "        signal_wd = word_lookup[word_idx]\n",
    "        pos_words.append(signal_wd)\n",
    "\n",
    "      negative_signal_words = np.argpartition(attributions, 5)[:5]\n",
    "      neg_words = []\n",
    "      for word_idx in negative_signal_words:\n",
    "        signal_wd = word_lookup[word_idx]\n",
    "        neg_words.append(signal_wd)\n",
    "      colorprint(test_qs[examples_to_print[i]],pos_words, neg_words)\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ovMDDAQtyo08"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "text-classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
